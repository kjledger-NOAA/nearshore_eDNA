---
title: "decontamination of pcr replicates and ASVs for nearshore samples and mock communities"
author: "Kimberly Ledger"
date: "2024-11-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

libraries
```{r}
library(tidyverse)
rename <- dplyr::rename
library(reshape2)
```

load sample metadata
```{r}
metadata <- read.csv("/home/kimberly.ledger/nearshore_eDNA/data/samples_w_mocks_updated/nearshore_metadata.csv") %>%
  rename(Sample_ID = sample_ID)
```

check sequence table outputs
```{r}
asv_table <- readRDS("/home/kimberly.ledger/nearshore_eDNA/data/samples_w_mocks_updated/filtered.seqTab.RDS") %>%
  select(!Row.names)

#transpose 
asv_table <- data.frame(t(asv_table))

#set column names to be ASV# 
colnames(asv_table) <- asv_table["ASV",]

#remove row that has ASV#
asv_table <- asv_table[!rownames(asv_table) %in% c('ASV'), ]

#make sure reads are numbers
# Convert all character columns to numeric
for (col in names(asv_table)) {
  asv_table[[col]] <- as.numeric(asv_table[[col]])
}

#make make sample ID a column 
asv_table$Sample_ID <- rownames(asv_table)

asv_table <- asv_table %>%
  select(Sample_ID, everything()) %>%
  mutate(Sample_ID = str_replace(Sample_ID, "^COM-", "COM"))
```

add column to the ASV table that labels the sample type
```{r}
asv_table_with_sample_type <- metadata %>%
  dplyr::select(Sample_ID, sample_type) %>%
  left_join(asv_table, by = "Sample_ID")

# make a variable for the first and last ASV column in the table
asv_first <- which(startsWith(names(asv_table_with_sample_type), "ASV"))[1]
asv_last <- ncol(asv_table_with_sample_type)
```


# account for likely contaminants 

step 1: tag-jumping: subtract the proportion of reads that jumped into the positive control samples from each environmental sample 
step 2: remove ASVs that don't get a fish taxonomic assignment 
step 3: remove any ASVs that don't show up in field samples 
step 4: remove low read depth samples based on ASV accumulation curve  
step 5: check dissimilarity across PCR replicates and remove any replicates with high dissimilarity 


## Step 1. Account for tag-jumping by using the positive controls 

subtract the proportion of reads that jumped into the positive control samples from each environmental sample 

plot the positive controls
```{r}
asv_table_with_sample_type %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = ifelse(is.na(reads), 0, reads)) %>%
  filter(sample_type %in% c("positive")) %>%
  filter(reads > 0) %>%
  ggplot(aes(x=Sample_ID, y=reads, fill=ASV)) +
  geom_bar(stat = "identity") + 
  theme_bw() +
  labs(
    y = "number of sequencing reads",
    x = "sample ID",
    title = "ASV reads - positive controls") + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.text = element_text(size = 8),
    legend.key.size = unit(0.3, "cm"),
    #legend.position = "none",
    legend.title = element_blank()
  )
```

identify the maximum proportion of reads for each ASV found in the positive controls
```{r}
prop_asvs_in_positives <- asv_table_with_sample_type %>%
  filter(sample_type == "positive") %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  group_by(Sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads)) %>%
  mutate(Prop = reads/TotalReadsPerSample) %>%
  group_by(ASV) %>%
  summarise(max_prop = max(Prop)) %>%
  arrange(desc(max_prop))
```

subtract the max proportion of tag-jumped reads for each ASV from samples
```{r}
indexhop_table <- asv_table_with_sample_type %>%
  pivot_longer(cols = c(asv_first:asv_last), names_to = "ASV", values_to = "reads") %>%
  mutate(reads = ifelse(is.na(reads), 0, reads)) %>%
  group_by(Sample_ID) %>%
  mutate(TotalReadsPerSample = sum(reads, na.rm = T)) %>%
  left_join(prop_asvs_in_positives, by = c("ASV")) %>%
  mutate(IndexHoppingReads = TotalReadsPerSample*max_prop) %>%
  mutate(reads_IndexHop_removed = reads - IndexHoppingReads) %>%
  mutate(reads_IndexHop_removed = if_else(reads_IndexHop_removed < 0, 0, reads_IndexHop_removed))
```

clean up the table by removing columns no longer needed 
```{r}
asv_table_filter1 <- indexhop_table %>%
  dplyr::select(Sample_ID, sample_type, ASV, reads_IndexHop_removed) %>%
  dplyr::rename(reads = reads_IndexHop_removed)
```

this is a summary of the number of reads removed by ASV and sample_ID
```{r}
decontaminated_1 <- indexhop_table %>%
  dplyr::select(Sample_ID, ASV, IndexHoppingReads) %>%
  pivot_wider(names_from = "ASV", values_from = "IndexHoppingReads")
```

## Step 2. Remove ASVs that don't get a fish taxonomic assignment  

```{r}
taxonomy <- read.csv("/home/kimberly.ledger/nearshore_eDNA/outputs/samples_w_mocks_updated/taxonomy_20241108_collapsed.csv") %>%
  select(!X) %>%
  rename(ASV = qseqid)

asv_table_filter2 <- asv_table_filter1 %>%
  filter(ASV %in% taxonomy$ASV)
```


## Step 3. Remove ASVs that do not occur in environmental samples

```{r}
reads_per_type_ASV <- asv_table_filter2 %>%
  group_by(ASV, sample_type) %>%
  summarize(TotalReadsPerASV = sum(reads, na.rm = TRUE)) %>%
  arrange(ASV)
```

what ASVs have no reads in samples, but reads in the controls? 
```{r}
not_in_samples <- reads_per_type_ASV %>%
  pivot_wider(names_from = "sample_type", values_from = c("TotalReadsPerASV")) %>%
    filter(sample < 1 & mock < 1)
not_in_samples
```

remove these from the asv table
```{r}
asv_table_filter3 <- asv_table_filter2 %>%
  filter(!ASV %in% not_in_samples$ASV)
```


## Step 4. Remove low read depth samples based on ASV accumulation curve

```{r}
library(vegan)

asv_table_wide <- asv_table_filter3 %>%
  select(!sample_type) %>%
  mutate(reads = as.integer(reads)) %>%
  pivot_wider(names_from = ASV, values_from = reads)

sample_IDs <- asv_table_wide$Sample_ID

asv_table_wide <- asv_table_wide %>%
  ungroup() %>%
  select(-Sample_ID)

## plots the figure
rarecurve(asv_table_wide, step = 20, col = "blue", label = FALSE, 
          main = "Sequencing Effort Curves",
          xlab = "Sequencing Depth", ylab = "Number of ASVs Identified",
          xlim = c(0,5000))
```

summarize in a table how many pcr replicates meet certain read count thresholds 
```{r}
read_summary <- asv_table_filter3 %>%
  group_by(Sample_ID, sample_type) %>%
  summarize(tot_reads = sum(reads)) %>%
  arrange(desc(tot_reads)) %>%
  group_by(sample_type) %>%
  summarize(atleast1 = sum(tot_reads >= 1),
            atleast250 = sum(tot_reads >= 250),
            atleast500 = sum(tot_reads >= 500),
            atleast750 = sum(tot_reads >= 750),
            atleast1k = sum(tot_reads >= 1000),
            atleast2k = sum(tot_reads >= 2000))
```

based on taxa accumulation curve and summary table, we will remove any pcr replicate with fewer than 1000 reads from downstream analyses

```{r}
reps_below <- asv_table_filter3 %>%
  group_by(Sample_ID) %>%
  summarise(tot_reads = sum(reads)) %>%
  filter(tot_reads < 1000)
```

```{r}
asv_table_filter4 <- asv_table_filter3 %>%
  filter(!Sample_ID %in% reps_below$Sample_ID)
```


```{r}
write.csv(asv_table_filter4, "/home/kimberly.ledger/nearshore_eDNA/outputs/samples_w_mocks_updated/decontaminated_asv_table.csv")
```


######### STOPPING HERE!

## Step 5. check pcr replicate dissimilarity in field samples 

are there any samples that have made it to this point that don't actually have any reads? 
```{r}
asv_table_filter4 %>%
  group_by(Sample_ID) %>%
  summarise(total_reads = sum(reads)) %>%
  arrange(total_reads)
```

how many pcr replicates does each extraction replicate have? 
```{r}
onerep <- asv_table_filter4  %>%
  separate(Sample_ID, into = c("bottle_ID", "replicate"), remove = F) %>%
  group_by(bottle_ID) %>%
  summarise(nrep = n_distinct(Sample_ID)) %>%
  filter(nrep == 1)
onerep

asv_table_filter4  %>%
  separate(Sample_ID, into = c("bottle_ID", "replicate"), remove = F) %>%
  group_by(bottle_ID) %>%
  summarise(nrep = n_distinct(Sample_ID)) %>%
  filter(nrep == 2)

asv_table_filter4  %>%
  separate(Sample_ID, into = c("bottle_ID", "replicate"), remove = F) %>%
  group_by(bottle_ID) %>%
  summarise(nrep = n_distinct(Sample_ID)) %>%
  filter(nrep == 3)
```

remove the bottles with only 1 pcr rep (there's one field blank and one extraction blank) and then calculate an eDNA index
```{r}
normalized <- asv_table_filter4 %>%
  separate(Sample_ID, into = c("bottle_ID", "replicate"), remove = F) %>%
  filter(!bottle_ID %in% onerep$bottle_ID) %>% 
  filter(sample_type == "sample" | sample_type == "mock") %>%
  group_by(Sample_ID) %>%
  mutate(Tot = sum(reads),
         Prop_reads = reads/Tot) %>%     ## calculate read proportions 
  ungroup() %>%
  dplyr::group_by(ASV) %>%
  mutate(Colmax = max(Prop_reads, na.rm = TRUE),
         Normalized_reads = Prop_reads/Colmax)   ## this normalized the proportion of reads for each ASV by dividing it by it's maximum value

#add back in some metadata - will use this for dissimilarity measures
normalized_w_meta <- normalized %>%
  left_join(metadata) %>%
  ### need to make objects to designate site and biological reps 
```

```{r}
tibble_to_matrix <- function (tb) {
  
  tb %>%
  #normalized %>%
    group_by(new_ID, ASV) %>% 
    summarise(nReads = sum(Normalized_reads)) %>% 
    spread ( key = "ASV", value = "nReads", fill = 0) %>%
    ungroup() -> matrix_1
    samples <- pull (matrix_1, new_ID)
    matrix_1[,-1] -> matrix_1
    data.matrix(matrix_1) -> matrix_1
    dimnames(matrix_1)[[1]] <- samples
    vegdist(matrix_1) -> matrix_1
}
```

will run this seperatly for kenai and kasilof
```{r}
all.distances.full <- tibble_to_matrix(normalized_w_meta)

# Do all samples have a name?
summary(is.na(names(all.distances.full)))
```

make the pairwise distances a long table
```{r}
as_tibble(subset(melt(as.matrix(all.distances.full)))) -> all.distances.melted

# Any major screw ups
summary(is.na(all.distances.melted$value))

# Now, create a three variables for all distances, they could be PCR replicates, BIOL replicates, or from the same site

all.distances.melted %>%
  separate (Var1, into = "Bottle1", sep = "\\-", remove = FALSE) %>%
  separate (Bottle1, into = "Site1", remove = FALSE) %>%
  separate (Var2, into ="Bottle2", sep = "\\-", remove = FALSE) %>%
  separate (Bottle2, into = "Site2", remove = FALSE) %>%
  mutate (Distance.type = case_when( Bottle1 == Bottle2 ~ "PCR Replicates",
                                      Site1 == Site2 ~ "Same Site",
                                      TRUE ~ "Different Site"
                                     )) %>%
  dplyr::select(Sample1 = Var1, Sample2 = Var2 , value , Distance.type) %>%
  filter (Sample1 != Sample2) -> all.distances.to.plot

# Checking all went well

sapply(all.distances.to.plot, function(x) summary(is.na(x)))
```

```{r}
all.distances.to.plot$Distance.type <- all.distances.to.plot$Distance.type  %>% fct_relevel("PCR Replicates", "Same Site")

ggplot (all.distances.to.plot) +
  geom_histogram (aes (fill = Distance.type, x = value, after_stat(ndensity)), position = "dodge",  alpha = 0.9, bins = 50) +
  facet_wrap( ~ Distance.type) +
  labs (x = "Pairwise dissimilarity", y = "density" ,
        Distance.type = "Distance",
        title = "") +
    guides (fill = "none")
```

this shows quite a bit a dissimilarity among PCR replicates...  

next i will follow what was done here:  (https://github.com/ramongallego/eDNA.and.Ocean.Acidification.Gallego.et.al.2020/blob/master/Scripts/Denoising.all.runs.Rmd) and instead of choosing outliers based on the pairwise distances, we can do a similar thing using the distance to centroid. 


now identify and discard outliers 
```{r message=FALSE, warning=FALSE}
normalized_w_meta %>%
  group_by(extraction_ID) %>% nest() -> nested.cleaning 

nested.cleaning %>% 
  mutate(matrix = map(data, tibble_to_matrix)) -> nested.cleaning

nested.cleaning %>% mutate(ncomparisons = map(matrix, length)) -> nested.cleaning
```

```{r}
dist_to_centroid <- function (x,y) {
  
  #biol <- rep(y, dim(x)[[1]])
  biol <- rep(y, length(x))
  
  if (length(biol) == 1) {
    output = rep(x[1]/2,2)
    names(output) <- attr(x, "Labels")
  }else{ 
    
  dispersion <- betadisper(x, group = biol)
  output = dispersion$distances
  }
  output
    }
```

```{r}
nested.cleaning.temp <- nested.cleaning %>% 
  mutate(distances = map2(matrix, extraction_ID, dist_to_centroid))

all_distances <- nested.cleaning.temp %>%
  unnest_longer(distances) %>%
  dplyr::select(extraction_ID, distances_id, distances)

hist(all_distances$distances)
```

remove the pcr replicates outside of 95% of the normal distribution of distances 
```{r}
normparams <- MASS::fitdistr(all_distances$distances, "normal")$estimate                                      
probs <- pnorm(all_distances$distances, normparams[1], normparams[2])
outliers_centroid <- which(probs>0.95)

discard_centroid <- all_distances$distances_id[outliers_centroid]
discard_centroid

#extraction_IDs with a pcr replicate discarded 
to_discard <- data.frame(discard_centroid) %>%
  separate(discard_centroid, into = c("location1", "extraction_ID", "pcr_replicate"))
```


which extraction/bottle ID have a pcr replicate that's recommended for removal? 
```{r}
removed_dissim <- normalized_w_meta %>%
  filter(extraction_ID %in% to_discard$extraction_ID)
```


these samples have at least one dissimilar pcr replicates 
```{r}
unique(removed_dissim$extraction_ID)

first_six <- unique(removed_dissim$extraction_ID)[1:6]

removed_dissim %>%
  filter(extraction_ID %in% first_six) %>%
  filter(reads > 0) %>%
  group_by(Sample_ID) %>%
  mutate(sum=sum(reads)) %>%
  mutate(prop = reads/sum) %>%
  ggplot(aes(x=Sample_ID, y=prop, fill=ASV)) +
  geom_bar(stat = "identity") + 
  facet_wrap(~extraction_ID, scales = 'free', ncol = 3) +
  theme_bw() + 
  theme(
    axis.text.x = element_text(angle = 90, hjust = 0.95),
    legend.position = "none",
    legend.title = element_blank()
  )  
```

now filter the asv table accordingly 
```{r}
to_discard <- data.frame(discard_centroid) %>%
  separate(discard_centroid, into = c("location1", "Sample_ID"), sep = "_")

asv_table_filter5 <- asv_table_filter4 %>%
  filter(!Sample_ID %in% to_discard$Sample_ID) %>%
  filter(!Sample_ID %in% c("e00512-C", "e00562-A")) %>% ## these are the samples with only one PCR replicate
  left_join(metadata) %>%
  filter(!is.na(location1)) %>%
  select(Sample_ID:reads)

no_read_ASVs <- asv_table_filter5 %>%
  group_by(ASV) %>%
  summarize(tot_reads = sum(reads)) %>%
  filter(tot_reads == 0)

asv_table_filter6 <- asv_table_filter5 %>%
  filter(!ASV %in% no_read_ASVs$ASV)
```


